{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "from operator import add\n",
    "from scipy import sparse\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sentence = nltk.corpus.treebank.tagged_sents(tagset='universal')\n",
    "tagged_words = list(set([tup for i in tagged_sentence for tup in i]))\n",
    "vocab = list(set([word for word, tag in tagged_words]))\n",
    "tags = list(set([tag for word, tag in tagged_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tagged_sentence[:int(len(tagged_sentence)*0.7)]\n",
    "test = tagged_sentence[int(len(tagged_sentence)*0.7+1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(sentence, t_prev, t_pres, index):\n",
    "    dic = {}\n",
    "    word = sentence[index]\n",
    "    dic[(word, t_pres)] = 1\n",
    "    if index == 0:\n",
    "        dic[('start', t_pres)] = 1\n",
    "    else:\n",
    "        dic[(t_prev, t_pres)] = 1\n",
    "        dic[('pre_w '+sentence[index - 1], t_pres)] = 1\n",
    "    if index <len(sentence)-1:\n",
    "        dic[('aft_w '+sentence[index + 1], t_pres)] = 1\n",
    "    else:\n",
    "        dic[(t_pres, 'end')] = 1\n",
    "    #if index >=2:\n",
    "     #   dic[(tag[index -2]+' '+tag[index-1], t_pres)] = 1\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_vector(sentence, tag):\n",
    "    for j in range(len(sentence)):\n",
    "        if j == 0:\n",
    "            v = feature_extractor(sentence,'start',tag[j],j)\n",
    "        else:\n",
    "            v = Counter(v) +Counter(feature_extractor(sentence, tag[j-1], tag[j], j))\n",
    "            v = dict(v)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product(alpha, f):\n",
    "    s = 0\n",
    "    for key in f.keys():\n",
    "        if key in alpha.keys():\n",
    "            s = s+ alpha[key]*f[key]\n",
    "        #else:\n",
    "           # alpha[key] = 0\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(alpha, sentence):\n",
    "    n = len(sentence)\n",
    "    t = [0]*n\n",
    "    score = [0]*n\n",
    "    state = [0]*n\n",
    "    y = [0]*n\n",
    "    curr_state_score = {}\n",
    "    curr_state = {}\n",
    "    last_state_score = {}\n",
    "    \n",
    "    for tag_ in tags:\n",
    "        curr_state_score[tag_] = product(alpha, feature_extractor(sentence, 'start', tag_, 0))\n",
    "        curr_state[tag_] = 'start'\n",
    "    score[0] = curr_state_score.copy()\n",
    "    state[0] = curr_state.copy()\n",
    "    for i in range(1, n):\n",
    "        last_state_score = curr_state_score.copy()\n",
    "        for tag_c in tags:\n",
    "            dic = {}\n",
    "            for tag_l in tags:\n",
    "                dic[tag_l] = last_state_score[tag_l]+product(alpha, feature_extractor(sentence, tag_l, tag_c, i))\n",
    "            curr_state_score[tag_c] = max(dic.values())\n",
    "            curr_state[tag_c] = max(dic, key=dic.get)\n",
    "        score[i] = curr_state_score.copy()\n",
    "        state[i] = curr_state.copy()\n",
    "    y[-1] = max(curr_state_score, key = curr_state_score.get)\n",
    "    for i in reversed(range(n-1)):\n",
    "        curr_state = state[i+1]\n",
    "        y[i] =  curr_state[y[i+1]]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(training_set, T, avg = False):\n",
    "    n = len(training_set)\n",
    "    alpha = {}\n",
    "    l = []\n",
    "    for t in range(T):\n",
    "        for i in range(n):\n",
    "            tagged_s = training_set[i]\n",
    "            tag = [tup[1] for tup in tagged_s ]\n",
    "            sentence = [tup[0] for tup in tagged_s]\n",
    "            z = Viterbi(alpha, sentence)\n",
    "            #print (z)\n",
    "            if z != tag:\n",
    "                alpha = Counter(alpha) + Counter(feature_vector(sentence, tag)) - Counter(feature_vector(sentence, z))\n",
    "                alpha = dict(alpha)\n",
    "                if avg == True:\n",
    "                    l.append(alpha)\n",
    "    if avg == True:\n",
    "        for al in l:\n",
    "            alpha = Counter(alpha) + Counter(al)\n",
    "        alpha = dict(alpha)\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = perceptron(train, 1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = {k: v /len(train) for k, v in alpha.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [tup[0] for tup in test[4]]\n",
    "tag = [tup[1] for tup in test[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tag)-set(Viterbi(alpha, sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err(test):\n",
    "    count_w = 0\n",
    "    dif = 0\n",
    "    for tagged_s in test:\n",
    "        sentence = [tup[0] for tup in tagged_s]\n",
    "        tag = [tup[1] for tup in tagged_s]\n",
    "        count_w  = count_w + len(sentence)\n",
    "        dif = dif + len(set(tag)-set(Viterbi(alpha, sentence)))\n",
    "    return dif/count_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010443070059819528"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9914"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1- 0.0086"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
